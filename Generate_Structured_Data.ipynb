{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI SDK version: 0.28.0\n",
      "Train+Dev convos: 9038 | Test convos: 1004\n",
      "Flow label count: 10 | Subflow label count: 96\n",
      "Test DataFrame shape: (10, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting (test): 100%|██████████| 10/10 [00:34<00:00,  3.44s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>convo_id</th>\n",
       "      <th>flow</th>\n",
       "      <th>subflow</th>\n",
       "      <th>transcript</th>\n",
       "      <th>extracted_flow</th>\n",
       "      <th>extracted_subflow</th>\n",
       "      <th>extracted_personal_customer_name</th>\n",
       "      <th>extracted_personal_email</th>\n",
       "      <th>extracted_personal_member_level</th>\n",
       "      <th>extracted_personal_phone</th>\n",
       "      <th>...</th>\n",
       "      <th>extracted_order_num_products</th>\n",
       "      <th>extracted_order_order_id</th>\n",
       "      <th>extracted_order_packaging</th>\n",
       "      <th>extracted_order_payment_method</th>\n",
       "      <th>extracted_order_products</th>\n",
       "      <th>extracted_order_purchase_date</th>\n",
       "      <th>extracted_order_state</th>\n",
       "      <th>extracted_order_zip_code</th>\n",
       "      <th>extracted_product_names</th>\n",
       "      <th>extracted_product_amounts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4989</td>\n",
       "      <td>storewide_query</td>\n",
       "      <td>timing_4</td>\n",
       "      <td>agent: Hello. How can i help you today? custom...</td>\n",
       "      <td>storewide_query</td>\n",
       "      <td>promo_code_out_of_date</td>\n",
       "      <td>Chloe Zhang</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4512</td>\n",
       "      <td>subscription_inquiry</td>\n",
       "      <td>manage_dispute_bill</td>\n",
       "      <td>agent: Hi! How may I help you? customer: Hello...</td>\n",
       "      <td>purchase_dispute</td>\n",
       "      <td>mistimed_billing_already_returned</td>\n",
       "      <td>Albert Sanders</td>\n",
       "      <td></td>\n",
       "      <td>silver</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>7149958247</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5063</td>\n",
       "      <td>single_item_query</td>\n",
       "      <td>shirt_how_3</td>\n",
       "      <td>agent: Hello! How can I help you today? custom...</td>\n",
       "      <td>single_item_query</td>\n",
       "      <td>shirt_how_1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[Tommy Hilifiger shirt]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1694</td>\n",
       "      <td>storewide_query</td>\n",
       "      <td>policy_3</td>\n",
       "      <td>agent: Hello, thank you for contacting us toda...</td>\n",
       "      <td>subscription_inquiry</td>\n",
       "      <td>manage_cancel</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8068</td>\n",
       "      <td>troubleshoot_site</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>agent: Hello, thank you for contacting AcmeCor...</td>\n",
       "      <td>manage_account</td>\n",
       "      <td>manage_payment_method</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>credit card</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7462</td>\n",
       "      <td>storewide_query</td>\n",
       "      <td>policy_2</td>\n",
       "      <td>agent: Thank you for shopping with AcmeBrands!...</td>\n",
       "      <td>storewide_query</td>\n",
       "      <td>policy_1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>silver</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3585</td>\n",
       "      <td>purchase_dispute</td>\n",
       "      <td>promo_code_invalid</td>\n",
       "      <td>agent: Hello, how can I help you today? custom...</td>\n",
       "      <td>purchase_dispute</td>\n",
       "      <td>promo_code_invalid</td>\n",
       "      <td>Alessandro Phoenix</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>9602071593</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[Michael Kors jeans]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1136</td>\n",
       "      <td>account_access</td>\n",
       "      <td>reset_2fa</td>\n",
       "      <td>agent: How can i help you today? customer: Hi!...</td>\n",
       "      <td>account_access</td>\n",
       "      <td>reset_2fa</td>\n",
       "      <td>Chloe Zhang</td>\n",
       "      <td>czhang14@email.com</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1601</td>\n",
       "      <td>single_item_query</td>\n",
       "      <td>boots_other_3</td>\n",
       "      <td>agent: Thanks for contacting Acme.  How may I ...</td>\n",
       "      <td>storewide_query</td>\n",
       "      <td>out_of_stock_one_item</td>\n",
       "      <td>Norman Bouchard</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>credit card</td>\n",
       "      <td>[\"Michael Kors boots, size 9\"]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[Michael Kors boots]</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5735</td>\n",
       "      <td>shipping_issue</td>\n",
       "      <td>status</td>\n",
       "      <td>agent: Hello! Thank you for choosing AcmeBrand...</td>\n",
       "      <td>shipping_issue</td>\n",
       "      <td>status_delivery_date</td>\n",
       "      <td>Joseph Banter</td>\n",
       "      <td>josephb3@email.com</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>9503594314</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   convo_id                  flow              subflow  \\\n",
       "0      4989       storewide_query             timing_4   \n",
       "1      4512  subscription_inquiry  manage_dispute_bill   \n",
       "2      5063     single_item_query          shirt_how_3   \n",
       "3      1694       storewide_query             policy_3   \n",
       "4      8068     troubleshoot_site          credit_card   \n",
       "5      7462       storewide_query             policy_2   \n",
       "6      3585      purchase_dispute   promo_code_invalid   \n",
       "7      1136        account_access            reset_2fa   \n",
       "8      1601     single_item_query        boots_other_3   \n",
       "9      5735        shipping_issue               status   \n",
       "\n",
       "                                          transcript        extracted_flow  \\\n",
       "0  agent: Hello. How can i help you today? custom...       storewide_query   \n",
       "1  agent: Hi! How may I help you? customer: Hello...      purchase_dispute   \n",
       "2  agent: Hello! How can I help you today? custom...     single_item_query   \n",
       "3  agent: Hello, thank you for contacting us toda...  subscription_inquiry   \n",
       "4  agent: Hello, thank you for contacting AcmeCor...        manage_account   \n",
       "5  agent: Thank you for shopping with AcmeBrands!...       storewide_query   \n",
       "6  agent: Hello, how can I help you today? custom...      purchase_dispute   \n",
       "7  agent: How can i help you today? customer: Hi!...        account_access   \n",
       "8  agent: Thanks for contacting Acme.  How may I ...       storewide_query   \n",
       "9  agent: Hello! Thank you for choosing AcmeBrand...        shipping_issue   \n",
       "\n",
       "                   extracted_subflow extracted_personal_customer_name  \\\n",
       "0             promo_code_out_of_date                      Chloe Zhang   \n",
       "1  mistimed_billing_already_returned                   Albert Sanders   \n",
       "2                        shirt_how_1                                    \n",
       "3                      manage_cancel                                    \n",
       "4              manage_payment_method                                    \n",
       "5                           policy_1                                    \n",
       "6                 promo_code_invalid               Alessandro Phoenix   \n",
       "7                          reset_2fa                      Chloe Zhang   \n",
       "8              out_of_stock_one_item                  Norman Bouchard   \n",
       "9               status_delivery_date                    Joseph Banter   \n",
       "\n",
       "  extracted_personal_email extracted_personal_member_level  \\\n",
       "0                                                            \n",
       "1                                                   silver   \n",
       "2                                                            \n",
       "3                                                            \n",
       "4                                                            \n",
       "5                                                   silver   \n",
       "6                                                            \n",
       "7       czhang14@email.com                                   \n",
       "8                                                            \n",
       "9       josephb3@email.com                                   \n",
       "\n",
       "  extracted_personal_phone  ... extracted_order_num_products  \\\n",
       "0                           ...                                \n",
       "1                           ...                                \n",
       "2                           ...                                \n",
       "3                           ...                                \n",
       "4                           ...                                \n",
       "5                           ...                                \n",
       "6                           ...                                \n",
       "7                           ...                                \n",
       "8                           ...                            1   \n",
       "9                           ...                                \n",
       "\n",
       "  extracted_order_order_id extracted_order_packaging  \\\n",
       "0                                                      \n",
       "1               7149958247                             \n",
       "2                                                      \n",
       "3                                                      \n",
       "4                                                      \n",
       "5                                                      \n",
       "6               9602071593                             \n",
       "7                                                      \n",
       "8                                                      \n",
       "9               9503594314                             \n",
       "\n",
       "  extracted_order_payment_method        extracted_order_products  \\\n",
       "0                                                             []   \n",
       "1                                                             []   \n",
       "2                                                             []   \n",
       "3                                                             []   \n",
       "4                    credit card                              []   \n",
       "5                                                             []   \n",
       "6                                                             []   \n",
       "7                                                             []   \n",
       "8                    credit card  [\"Michael Kors boots, size 9\"]   \n",
       "9                                                             []   \n",
       "\n",
       "  extracted_order_purchase_date extracted_order_state  \\\n",
       "0                                                       \n",
       "1                                                       \n",
       "2                                                       \n",
       "3                                                       \n",
       "4                                                       \n",
       "5                                                       \n",
       "6                                                       \n",
       "7                                                       \n",
       "8                                                       \n",
       "9                                                       \n",
       "\n",
       "  extracted_order_zip_code  extracted_product_names extracted_product_amounts  \n",
       "0                                                []                        []  \n",
       "1                                                []                        []  \n",
       "2                           [Tommy Hilifiger shirt]                        []  \n",
       "3                                                []                        []  \n",
       "4                                                []                        []  \n",
       "5                                                []                        []  \n",
       "6                              [Michael Kors jeans]                        []  \n",
       "7                                                []                        []  \n",
       "8                              [Michael Kors boots]                       [1]  \n",
       "9                                                []                        []  \n",
       "\n",
       "[10 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test flow accuracy: 60.00%\n",
      "Test subflow accuracy: 20.00%\n"
     ]
    }
   ],
   "source": [
    "# === TEST-SET EVAL with smart label sets (Colab, OpenAI 0.28, no env vars) ===\n",
    "!pip -q install \"openai==0.28\" pandas tqdm\n",
    "\n",
    "import os, json, gzip, time, difflib\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, Any, List, Tuple\n",
    "from getpass import getpass\n",
    "import openai\n",
    "\n",
    "print(\"OpenAI SDK version:\", openai.__version__)\n",
    "\n",
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "FILE_PATH         = \"abcd_v1.1.json\"   # use full dataset if you have it; fallback to \"abcd_sample.json\"\n",
    "ONTOLOGY_PATH     = \"data/ontology.json\"    # optional; enrich label sets if present\n",
    "PRIMARY_MODEL     = \"gpt-4o\"           # try \"gpt-4o\" if you have access\n",
    "FALLBACK_MODELS   = [\"gpt-4o\", \"gpt-3.5-turbo-0125\"]\n",
    "MAX_TEST_SAMPLES  = 10                      # cap for cost\n",
    "REQUEST_DELAY_SEC = 0.7\n",
    "\n",
    "# -----------------------------\n",
    "# API key (no env vars)\n",
    "# -----------------------------\n",
    "openai.api_key = getpass(\"Enter your OpenAI API key (will not echo): \")\n",
    "\n",
    "def safe_chat(messages, model):\n",
    "    try:\n",
    "        resp = openai.ChatCompletion.create(model=model, messages=messages, temperature=0)\n",
    "        return resp[\"choices\"][0][\"message\"].get(\"content\",\"\") if resp.get(\"choices\") else \"\"\n",
    "    except Exception as e:\n",
    "        print(f\"[chat:{model}] error: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# -----------------------------\n",
    "# IO helpers\n",
    "# -----------------------------\n",
    "def load_json_maybe_gz(path: str):\n",
    "    if not os.path.exists(path):\n",
    "        gz = path + \".gz\"\n",
    "        if os.path.exists(gz):\n",
    "            path = gz\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"Could not find {path}\")\n",
    "    with open(path, \"rb\") as f:\n",
    "        is_gz = f.read(2) == b\"\\x1f\\x8b\"\n",
    "    opener = gzip.open if is_gz else open\n",
    "    with opener(path, \"rt\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def convo_to_transcript(convo: Dict[str,Any]) -> str:\n",
    "    orig = convo.get(\"original\", [])\n",
    "    return \" \".join([f\"{sp}: {tx}\" for sp, tx in orig])\n",
    "\n",
    "# -----------------------------\n",
    "# Load dataset\n",
    "# -----------------------------\n",
    "try:\n",
    "    abcd = load_json_maybe_gz(FILE_PATH)\n",
    "except FileNotFoundError:\n",
    "    # fallback: sample file in CWD\n",
    "    FILE_PATH = \"abcd_sample.json\"\n",
    "    abcd = load_json_maybe_gz(FILE_PATH)\n",
    "\n",
    "sample_mode = isinstance(abcd, list)\n",
    "if sample_mode:\n",
    "    print(\"Detected sample-style file (list). We'll split it 50/50 for demo.\")\n",
    "    n = len(abcd)\n",
    "    train_dev = abcd[: max(1, n//2)]\n",
    "    test_split = abcd[max(1, n//2):]\n",
    "else:\n",
    "    train_dev = (abcd.get(\"train\", []) or []) + (abcd.get(\"dev\", []) or [])\n",
    "    test_split = (abcd.get(\"test\", []) or [])\n",
    "\n",
    "print(f\"Train+Dev convos: {len(train_dev)} | Test convos: {len(test_split)}\")\n",
    "if len(test_split) == 0:\n",
    "    raise RuntimeError(\"No test split found. Point FILE_PATH to abcd_v1.1.json(.gz) or keep sample file.\")\n",
    "\n",
    "# -----------------------------\n",
    "# Build label sets\n",
    "#  - full dataset: from train+dev only (no test leakage)\n",
    "#  - sample file (very tiny): if too few labels found, broaden using ALL items in sample\n",
    "#  - ontology.json (if present): optionally enrich choices\n",
    "# -----------------------------\n",
    "def labels_from_convos(convos: List[Dict[str,Any]]) -> Tuple[List[str], List[str]]:#TODO:I need to add all labels\n",
    "    flows, subs = set(), set()\n",
    "    for c in convos:\n",
    "        sc = c.get(\"scenario\", {})\n",
    "        f  = sc.get(\"flow\", \"\")\n",
    "        sf = sc.get(\"subflow\", \"\")\n",
    "        if f:  flows.add(str(f))\n",
    "        if sf: subs.add(str(sf))\n",
    "    return sorted(flows), sorted(subs)\n",
    "\n",
    "flow_opts, subflow_opts = labels_from_convos(train_dev)\n",
    "\n",
    "# Optional: enrich from ontology.json (won't leak test labels semantically, just adds known valid strings)\n",
    "if os.path.exists(ONTOLOGY_PATH):\n",
    "    try:\n",
    "        onto = load_json_maybe_gz(ONTOLOGY_PATH)\n",
    "        strings = set()\n",
    "        def walk(x):\n",
    "            if isinstance(x, dict):\n",
    "                for k,v in x.items():\n",
    "                    if isinstance(k,str): strings.add(k)\n",
    "                    walk(v)\n",
    "            elif isinstance(x, list):\n",
    "                for i in x: walk(i)\n",
    "            elif isinstance(x, str):\n",
    "                strings.add(x)\n",
    "        walk(onto)\n",
    "        # Keep only ontology strings that look like our labels (heuristic: must contain underscore or be present in any split)\n",
    "        all_fl, all_sf = labels_from_convos(((abcd if sample_mode else (abcd.get(\"train\", []) + abcd.get(\"dev\", []) + abcd.get(\"test\", []))) if abcd else []))\n",
    "        candidates = {s for s in strings if (\"_\" in s) or (s in all_fl) or (s in all_sf)}\n",
    "        flow_opts = sorted(set(flow_opts) | ( candidates & set(all_fl) ))\n",
    "        subflow_opts = sorted(set(subflow_opts) | ( candidates & set(all_sf) ))\n",
    "    except Exception as e:\n",
    "        print(f\"[ontology] Could not parse {ONTOLOGY_PATH}: {e}. Continuing with train/dev labels.\")\n",
    "\n",
    "# If sample is too tiny (e.g., only 1 label each), broaden using all items in sample\n",
    "if sample_mode and (len(flow_opts) < 2 or len(subflow_opts) < 2):\n",
    "    all_fl, all_sf = labels_from_convos(abcd)\n",
    "    if len(flow_opts) < 2:     flow_opts = all_fl\n",
    "    if len(subflow_opts) < 2:  subflow_opts = all_sf\n",
    "    print(\"[sample] Broadened label sets using all sample convos.\")\n",
    "\n",
    "print(f\"Flow label count: {len(flow_opts)} | Subflow label count: {len(subflow_opts)}\")\n",
    "\n",
    "# -----------------------------\n",
    "# JSON schema + parsing\n",
    "# -----------------------------\n",
    "SCHEMA = {\n",
    "  \"personal\": {\"customer_name\":\"\",\"email\":\"\",\"member_level\":\"\",\"phone\":\"\",\"username\":\"\"},\n",
    "  \"order\": {\"street_address\":\"\",\"full_address\":\"\",\"city\":\"\",\"num_products\":\"\",\"order_id\":\"\",\n",
    "            \"packaging\":\"\",\"payment_method\":\"\",\"products\":\"[]\",\"purchase_date\":\"\",\"state\":\"\",\"zip_code\":\"\"},\n",
    "  \"product\": {\"names\":[],\"amounts\":[]},\n",
    "  \"flow\": \"\",\n",
    "  \"subflow\": \"\"\n",
    "}\n",
    "\n",
    "def try_parse_json(text: str):\n",
    "    if not text: return None\n",
    "    text = text.strip()\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except Exception:\n",
    "        s, e = text.find(\"{\"), text.rfind(\"}\")\n",
    "        if s != -1 and e != -1 and e > s:\n",
    "            cand = text[s:e+1]\n",
    "            try:\n",
    "                return json.loads(cand)\n",
    "            except Exception:\n",
    "                return None\n",
    "    return None\n",
    "\n",
    "def closest_label(pred: str, choices: List[str], cutoff: float = 0.6) -> str:\n",
    "    if not pred or not choices:\n",
    "        return \"\"\n",
    "    if pred in choices:\n",
    "        return pred\n",
    "    # case-insensitive exact first\n",
    "    lowmap = {c.lower(): c for c in choices}\n",
    "    if pred.lower() in lowmap:\n",
    "        return lowmap[pred.lower()]\n",
    "    # fuzzy match to nearest valid label\n",
    "    best = difflib.get_close_matches(pred, choices, n=1, cutoff=cutoff)\n",
    "    return best[0] if best else \"\"\n",
    "\n",
    "# -----------------------------\n",
    "# Extractor with constrained choices\n",
    "# -----------------------------\n",
    "def extract_metadata_from_transcript(transcript: str,\n",
    "                                     flow_choices: List[str],\n",
    "                                     subflow_choices: List[str]) -> Dict[str, Any]:\n",
    "    label_instr = (\n",
    "        \"CLASSIFICATION CONSTRAINTS:\\n\"\n",
    "        f\"- Valid flow labels (pick exactly one, copy verbatim): {flow_choices}\\n\"\n",
    "        f\"- Valid subflow labels (pick exactly one, copy verbatim): {subflow_choices}\\n\"\n",
    "        \"- Do NOT invent new labels. If uncertain, pick the most likely from the lists.\\n\"\n",
    "    )\n",
    "    prompt = (\n",
    "        \"Convert the customer-support dialog into structured metadata.\\n\\n\"\n",
    "        f\"{label_instr}\\n\"\n",
    "        \"OUTPUT RULES:\\n\"\n",
    "        \"- Return STRICT JSON only (no prose, no markdown).\\n\"\n",
    "        \"- Use this exact schema and field types:\\n\"\n",
    "        f\"{json.dumps(SCHEMA, indent=2)}\\n\"\n",
    "        \"- If a field is missing, use \\\"\\\" or [] accordingly.\\n\"\n",
    "        \"- 'flow' and 'subflow' MUST be exactly one of the provided labels above.\\n\\n\"\n",
    "        \"Dialog transcript:\\n\"\n",
    "        f\"{transcript}\\n\"\n",
    "    )\n",
    "    messages = [\n",
    "        {\"role\":\"system\",\"content\":\"Always return valid JSON that exactly matches the schema. No explanations.\"},\n",
    "        {\"role\":\"user\",\"content\":prompt}\n",
    "    ]\n",
    "    models_to_try = [PRIMARY_MODEL] + [m for m in FALLBACK_MODELS if m != PRIMARY_MODEL]\n",
    "    for m in models_to_try:\n",
    "        content = safe_chat(messages, m)\n",
    "        data = try_parse_json(content)\n",
    "        if isinstance(data, dict):\n",
    "            out = json.loads(json.dumps(SCHEMA))\n",
    "            for k,v in data.items():\n",
    "                out[k] = v\n",
    "            # enforce / normalize labels\n",
    "            out[\"flow\"]    = closest_label(out.get(\"flow\",\"\"), flow_choices, cutoff=0.6)\n",
    "            out[\"subflow\"] = closest_label(out.get(\"subflow\",\"\"), subflow_choices, cutoff=0.6)\n",
    "            return out\n",
    "        if content:\n",
    "            print(f\"[warn:{m}] unparsable output (first 160 chars): {content[:160]}\")\n",
    "        time.sleep(REQUEST_DELAY_SEC)\n",
    "    return json.loads(json.dumps(SCHEMA))\n",
    "\n",
    "# -----------------------------\n",
    "# Build TEST dataframe\n",
    "# -----------------------------\n",
    "test_rows = []\n",
    "for convo in test_split[:MAX_TEST_SAMPLES]:\n",
    "    sc = convo.get(\"scenario\", {})\n",
    "    test_rows.append({\n",
    "        \"convo_id\": convo.get(\"convo_id\",\"\"),\n",
    "        \"flow\": sc.get(\"flow\",\"\"),\n",
    "        \"subflow\": sc.get(\"subflow\",\"\"),\n",
    "        \"transcript\": convo_to_transcript(convo)\n",
    "    })\n",
    "test_df = pd.DataFrame(test_rows)\n",
    "print(\"Test DataFrame shape:\", test_df.shape)\n",
    "\n",
    "# -----------------------------\n",
    "# Predict on TEST only\n",
    "# -----------------------------\n",
    "preds = []\n",
    "for t in tqdm(test_df[\"transcript\"], desc=\"Predicting (test)\"):\n",
    "    preds.append(extract_metadata_from_transcript(t, flow_opts, subflow_opts))\n",
    "    time.sleep(REQUEST_DELAY_SEC)\n",
    "\n",
    "extracted = pd.json_normalize(preds, sep=\"_\").add_prefix(\"extracted_\")\n",
    "final_df  = pd.concat([test_df.reset_index(drop=True), extracted.reset_index(drop=True)], axis=1)\n",
    "\n",
    "display(final_df.head(50))\n",
    "\n",
    "# -----------------------------\n",
    "# Accuracy\n",
    "# -----------------------------\n",
    "for field in [\"flow\",\"subflow\"]:\n",
    "    gt = final_df[field].astype(str).fillna(\"\")\n",
    "    ex = final_df[f\"extracted_{field}\"].astype(str).fillna(\"\")\n",
    "    acc = (gt == ex).mean()\n",
    "    print(f\"Test {field} accuracy: {acc:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_df[[\"flow\",\"subflow\"]].nunique\n",
    "display(sorted(final_df[\"flow\"].unique()), sorted(final_df[\"subflow\"].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I noticed there are some extracted values that are not derived from actual available value options;\n",
    "\n",
    "Below is my implementation of the notebook above:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intall and Imports\n",
    "\n",
    "!pip -q install \"openai==0.28\" pandas tqdm # OpenAI (v0.28), Pandas, and tqdm\n",
    "\n",
    "import os, json, gzip, time, difflib\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, Any, List, Tuple\n",
    "from getpass import getpass\n",
    "import openai\n",
    "\n",
    "print(\"OpenAI SDK version:\", openai.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration and API Key Request\n",
    "\n",
    "FILE_PATH         = \"DATA/abcd_v1.1.json\"   \n",
    "ONTOLOGY_PATH     = \"DATA/ontology.json\" # optional; enrich label sets if present\n",
    "PRIMARY_MODEL     = \"gpt-4o\" \n",
    "FALLBACK_MODELS   = [\"gpt-4o\", \"gpt-3.5-turbo-0125\"]\n",
    "MAX_TEST_SAMPLES  = 10 # Cap for cost. Use 250 at max\n",
    "REQUEST_DELAY_SEC = 0.7\n",
    "\n",
    "openai.api_key = getpass(\"Enter your OpenAI API key (will not echo): \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "def call_chat_model_safely(messages, model):\n",
    "    try:\n",
    "        resp = openai.ChatCompletion.create(model=model, messages=messages, temperature=0)\n",
    "        return resp[\"choices\"][0][\"message\"].get(\"content\",\"\") if resp.get(\"choices\") else \"\"\n",
    "    except Exception as e:\n",
    "        print(f\"[chat:{model}] error: {e}\")\n",
    "        return \"\" \n",
    "    \n",
    "def load_json(path: str):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "def convo_to_transcript(convo: Dict[str,Any]) -> str:\n",
    "    orig = convo.get(\"original\", [])\n",
    "    return \" \".join([f\"{sp}: {tx}\" for sp, tx in orig])\n",
    "\n",
    "def labels_from_convos(convos: List[Dict[str,Any]]) -> Tuple[List[str], List[str]]:#TODO:I need to add all labels\n",
    "    flows, subs = set(), set()\n",
    "    for c in convos:\n",
    "        sc = c.get(\"scenario\", {})\n",
    "        f  = sc.get(\"flow\", \"\")\n",
    "        sf = sc.get(\"subflow\", \"\")\n",
    "        if f:  flows.add(str(f))\n",
    "        if sf: subs.add(str(sf))\n",
    "    return sorted(flows), sorted(subs)\n",
    "\n",
    "def try_parse_json(text: str):\n",
    "    if not text: return None\n",
    "    text = text.strip()\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except Exception:\n",
    "        s, e = text.find(\"{\"), text.rfind(\"}\")\n",
    "        if s != -1 and e != -1 and e > s:\n",
    "            cand = text[s:e+1]\n",
    "            try:\n",
    "                return json.loads(cand)\n",
    "            except Exception:\n",
    "                return None\n",
    "    return None\n",
    "\n",
    "def closest_label(pred: str, choices: List[str], cutoff: float = 0.6) -> str:\n",
    "    if not pred or not choices:\n",
    "        return \"\"\n",
    "    if pred in choices:\n",
    "        return pred\n",
    "    # Case-insensitive exact first\n",
    "    lowmap = {c.lower(): c for c in choices}\n",
    "    if pred.lower() in lowmap:\n",
    "        return lowmap[pred.lower()]\n",
    "    # Fuzzy match to nearest valid label\n",
    "    best = difflib.get_close_matches(pred, choices, n=1, cutoff=cutoff)\n",
    "    return best[0] if best else \"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset & Split into Train, Dev, and Test\n",
    "\n",
    "abcd = load_json(FILE_PATH)\n",
    "train_split = (abcd.get(\"train\", []) or [])\n",
    "dev_split = (abcd.get(\"dev\", []) or [])\n",
    "test_split = (abcd.get(\"test\", []) or [])\n",
    "print(f\"Train convos: {len(train_split)} | Dev convos: {len(dev_split)} | Test convos: {len(test_split)}\")\n",
    "\n",
    "\n",
    "# TODO: Gather 250 random seeded values in a variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build label sets\n",
    "\n",
    "SCHEMA = {\n",
    "  \"personal\": {\"customer_name\":\"\",\"email\":\"\",\"member_level\":\"\",\"phone\":\"\",\"username\":\"\"},\n",
    "  \"order\": {\"street_address\":\"\",\"full_address\":\"\",\"city\":\"\",\"num_products\":\"\",\"order_id\":\"\",\n",
    "            \"packaging\":\"\",\"payment_method\":\"\",\"products\":\"[]\",\"purchase_date\":\"\",\"state\":\"\",\"zip_code\":\"\"},\n",
    "  \"product\": {\"names\":[],\"amounts\":[]},\n",
    "  \"flow\": \"\",\n",
    "  \"subflow\": \"\"\n",
    "}\n",
    "\n",
    "def labels_from_convos(convos: List[Dict[str,Any]]) -> Tuple[List[str], List[str]]:#TODO:I need to add all labels\n",
    "    flows, subs = set(), set()\n",
    "    for c in convos:\n",
    "        sc = c.get(\"scenario\", {})\n",
    "        f  = sc.get(\"flow\", \"\")\n",
    "        sf = sc.get(\"subflow\", \"\")\n",
    "        if f:  flows.add(str(f))\n",
    "        if sf: subs.add(str(sf))\n",
    "    return sorted(flows), sorted(subs)\n",
    "\n",
    "flow_opts, subflow_opts = labels_from_convos(train_split+dev_split)\n",
    "\n",
    "if os.path.exists(ONTOLOGY_PATH):\n",
    "    try:\n",
    "        onto = load_json_maybe_gz(ONTOLOGY_PATH)\n",
    "        strings = set()\n",
    "        def walk(x):\n",
    "            if isinstance(x, dict):\n",
    "                for k,v in x.items():\n",
    "                    if isinstance(k,str): strings.add(k)\n",
    "                    walk(v)\n",
    "            elif isinstance(x, list):\n",
    "                for i in x: walk(i)\n",
    "            elif isinstance(x, str):\n",
    "                strings.add(x)\n",
    "        walk(onto)\n",
    "        # Keep only ontology strings that look like our labels (heuristic: must contain underscore or be present in any split)\n",
    "        all_fl, all_sf = labels_from_convos(((abcd if sample_mode else (abcd.get(\"train\", []) + abcd.get(\"dev\", []) + abcd.get(\"test\", []))) if abcd else []))\n",
    "        candidates = {s for s in strings if (\"_\" in s) or (s in all_fl) or (s in all_sf)}\n",
    "        flow_opts = sorted(set(flow_opts) | ( candidates & set(all_fl) ))\n",
    "        subflow_opts = sorted(set(subflow_opts) | ( candidates & set(all_sf) ))\n",
    "    except Exception as e:\n",
    "        print(f\"[ontology] Could not parse {ONTOLOGY_PATH}: {e}. Continuing with train/dev labels.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt Configuration\n",
    "\n",
    "# -----------------------------\n",
    "# Extractor with constrained choices\n",
    "# -----------------------------\n",
    "SCHEMA = {\n",
    "  \"personal\": {\"customer_name\":\"\",\"email\":\"\",\"member_level\":\"\",\"phone\":\"\",\"username\":\"\"},\n",
    "  \"order\": {\"street_address\":\"\",\"full_address\":\"\",\"city\":\"\",\"num_products\":\"\",\"order_id\":\"\",\n",
    "            \"packaging\":\"\",\"payment_method\":\"\",\"products\":\"[]\",\"purchase_date\":\"\",\"state\":\"\",\"zip_code\":\"\"},\n",
    "  \"product\": {\"names\":[],\"amounts\":[]},\n",
    "  \"flow\": \"\",\n",
    "  \"subflow\": \"\"\n",
    "}\n",
    "\n",
    "def extract_metadata_from_transcript(transcript: str,\n",
    "                                     flow_choices: List[str],\n",
    "                                     subflow_choices: List[str]) -> Dict[str, Any]:\n",
    "    label_instr = (\n",
    "        \"CLASSIFICATION CONSTRAINTS:\\n\"\n",
    "        f\"- Valid flow labels (pick exactly one, copy verbatim): {flow_choices}\\n\"\n",
    "        f\"- Valid subflow labels (pick exactly one, copy verbatim): {subflow_choices}\\n\"\n",
    "        \"- Do NOT invent new labels. If uncertain, pick the most likely from the lists.\\n\"\n",
    "    )\n",
    "    prompt = (\n",
    "        \"Convert the customer-support dialog into structured metadata.\\n\\n\"\n",
    "        f\"{label_instr}\\n\"\n",
    "        \"OUTPUT RULES:\\n\"\n",
    "        \"- Return STRICT JSON only (no prose, no markdown).\\n\"\n",
    "        \"- Use this exact schema and field types:\\n\"\n",
    "        f\"{json.dumps(SCHEMA, indent=2)}\\n\"\n",
    "        \"- If a field is missing, use \\\"\\\" or [] accordingly.\\n\"\n",
    "        \"- 'flow' and 'subflow' MUST be exactly one of the provided labels above.\\n\\n\"\n",
    "        \"Dialog transcript:\\n\"\n",
    "        f\"{transcript}\\n\"\n",
    "    )\n",
    "    messages = [\n",
    "        {\"role\":\"system\",\"content\":\"Always return valid JSON that exactly matches the schema. No explanations.\"},\n",
    "        {\"role\":\"user\",\"content\":prompt}\n",
    "    ]\n",
    "    models_to_try = [PRIMARY_MODEL] + [m for m in FALLBACK_MODELS if m != PRIMARY_MODEL]\n",
    "    for m in models_to_try:\n",
    "        content = safe_chat(messages, m)\n",
    "        data = try_parse_json(content)\n",
    "        if isinstance(data, dict):\n",
    "            out = json.loads(json.dumps(SCHEMA))\n",
    "            for k,v in data.items():\n",
    "                out[k] = v\n",
    "            # enforce / normalize labels\n",
    "            out[\"flow\"]    = closest_label(out.get(\"flow\",\"\"), flow_choices, cutoff=0.6)\n",
    "            out[\"subflow\"] = closest_label(out.get(\"subflow\",\"\"), subflow_choices, cutoff=0.6)\n",
    "            return out\n",
    "        if content:\n",
    "            print(f\"[warn:{m}] unparsable output (first 160 chars): {content[:160]}\")\n",
    "        time.sleep(REQUEST_DELAY_SEC)\n",
    "    return json.loads(json.dumps(SCHEMA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Prompt on Training Dataset\n",
    "\n",
    "# -----------------------------\n",
    "# Build TEST dataframe\n",
    "# -----------------------------\n",
    "test_rows = []\n",
    "for convo in test_split[:MAX_TEST_SAMPLES]:\n",
    "    sc = convo.get(\"scenario\", {})\n",
    "    test_rows.append({\n",
    "        \"convo_id\": convo.get(\"convo_id\",\"\"),\n",
    "        \"flow\": sc.get(\"flow\",\"\"),\n",
    "        \"subflow\": sc.get(\"subflow\",\"\"),\n",
    "        \"transcript\": convo_to_transcript(convo)#TODO: I have to add the other actual features here\n",
    "    })\n",
    "test_df = pd.DataFrame(test_rows)\n",
    "print(\"Test DataFrame shape:\", test_df.shape)\n",
    "\n",
    "# -----------------------------\n",
    "# Predict on TEST only\n",
    "# -----------------------------\n",
    "preds = []\n",
    "for t in tqdm(test_df[\"transcript\"], desc=\"Predicting (test)\"):\n",
    "    preds.append(extract_metadata_from_transcript(t, flow_opts, subflow_opts))#TODO: Add other features\n",
    "    time.sleep(REQUEST_DELAY_SEC)\n",
    "\n",
    "extracted = pd.json_normalize(preds, sep=\"_\").add_prefix(\"extracted_\")\n",
    "final_df  = pd.concat([test_df.reset_index(drop=True), extracted.reset_index(drop=True)], axis=1)\n",
    "\n",
    "display(final_df.head(50))\n",
    "\n",
    "# -----------------------------\n",
    "# Accuracy\n",
    "# -----------------------------\n",
    "for field in [\"flow\",\"subflow\"]:#TODO: Add other features for comparison\n",
    "    gt = final_df[field].astype(str).fillna(\"\")\n",
    "    ex = final_df[f\"extracted_{field}\"].astype(str).fillna(\"\")\n",
    "    acc = (gt == ex).mean()\n",
    "    print(f\"Test {field} accuracy: {acc:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
